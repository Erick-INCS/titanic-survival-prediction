{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  titanic.zip\n",
      "  inflating: gender_submission.csv   \n",
      "  inflating: test.csv                \n",
      "  inflating: train.csv               \n"
     ]
    }
   ],
   "source": [
    "!unzip titanic.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processDf(df, split = True, separate=None):\n",
    "    del df['Name']\n",
    "    del df['PassengerId']\n",
    "    del df['Ticket']\n",
    "    df.Cabin = df.Cabin.fillna('-')\n",
    "    \n",
    "    if split:\n",
    "        df = df.dropna()\n",
    "        \n",
    "    df.Pclass = df.Pclass.astype('str')\n",
    "    df = pd.get_dummies(df)\n",
    "    \n",
    "    maxAge = max(df['Age'])\n",
    "    \n",
    "    validKeys = ['Age', 'SibSp', 'Pclass_1', 'Pclass_2', 'Sex_female', 'Cabin_-',\n",
    "       'Cabin_A23', 'Cabin_B41', 'Cabin_C49', 'Cabin_D56', 'Cabin_E10',\n",
    "       'Cabin_E25', 'Cabin_F2', 'Cabin_F4']\n",
    "    \n",
    "    if separate != None:\n",
    "        separate = df[separate]\n",
    "    \n",
    "    for k in df.keys():\n",
    "        if k not in validKeys:\n",
    "            del df[k]\n",
    "    \n",
    "    # adjust order\n",
    "    orderedDf = pd.DataFrame()\n",
    "\n",
    "    for k in validKeys:\n",
    "        if k not in df:\n",
    "            print(k)\n",
    "            df[k] = 0\n",
    "        df[k] = df[k].fillna(df[k].mean())\n",
    "        \n",
    "        orderedDf[k] = df[k]\n",
    "    \n",
    "    orderedDf['Age'] = orderedDf['Age']/maxAge\n",
    "    \n",
    "    #split\n",
    "    if split:\n",
    "        train_size = 0.7\n",
    "        splitPoint = math.floor(len(orderedDf) * train_size)\n",
    "\n",
    "        dataset = orderedDf.values\n",
    "#         np.random.shuffle(dataset)\n",
    "        \n",
    "        x_train = dataset[:splitPoint,:]\n",
    "        y_train = separate[:splitPoint]\n",
    "\n",
    "        x_test = dataset[splitPoint:]\n",
    "        y_test = separate[splitPoint:]\n",
    "    else:\n",
    "        x_train = orderedDf.values\n",
    "        y_train = None\n",
    "        x_test = None\n",
    "        y_test = None\n",
    "        \n",
    "    return {\n",
    "        'x_train':x_train,\n",
    "        'y_train':y_train,\n",
    "        'x_test':x_test,\n",
    "        'y_test':y_test,\n",
    "        'separated':separate\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"train.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train X: (498, 14)\n",
      "Train Y: (498,) \n",
      "\n",
      "Test X: (214, 14)\n",
      "Test Y: (214,) \n",
      "\n",
      "All X: (712, 14)\n",
      "All Y: (712,) \n",
      "\n",
      "X shuffle: (712, 14)\n",
      "Y shuffle: (712,)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"train.csv\")\n",
    "tmp = processDf(df, separate='Survived')\n",
    "x_train = tmp['x_train']\n",
    "y_train = tmp['y_train'] \n",
    "x_test = tmp['x_test'] \n",
    "y_test = tmp['y_test'] \n",
    "\n",
    "all_x = np.append(x_train, x_test, 0)\n",
    "all_y = np.append(y_train, y_test, 0)\n",
    "\n",
    "x_shuffle = np.append(all_x, np.array([all_y]).reshape(len(all_x), 1), 1)\n",
    "np.random.shuffle(x_shuffle)\n",
    "y_shuffle = x_shuffle[:,-1]\n",
    "x_shuffle = x_shuffle[:,:-1]\n",
    "\n",
    "print(\"Train X:\", x_train.shape)\n",
    "print(\"Train Y:\", y_train.shape, \"\\n\")\n",
    "\n",
    "print(\"Test X:\", x_test.shape)\n",
    "print(\"Test Y:\", y_test.shape, \"\\n\")\n",
    "\n",
    "print(\"All X:\", all_x.shape)\n",
    "print(\"All Y:\", all_y.shape, \"\\n\")\n",
    "\n",
    "print(\"X shuffle:\", x_shuffle.shape)\n",
    "print(\"Y shuffle:\", y_shuffle.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(y_pred, y_real):\n",
    "    return np.sum(y_pred == y_real)/len(y_real)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 2690)              45730     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1530)              4117230   \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1530)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 930)               1423830   \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 940)               875140    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 940)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 610)               574010    \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 380)               232180    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 380)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 220)               83820     \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 221       \n",
      "=================================================================\n",
      "Total params: 7,352,161\n",
      "Trainable params: 7,352,161\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# DNN\n",
    "dnn = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(2690, input_shape=[x_shuffle.shape[1] + 2], activation='relu'),\n",
    "    tf.keras.layers.Dense(1530, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(930, activation='relu'),\n",
    "    tf.keras.layers.Dense(940, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(610, activation='relu'),\n",
    "    tf.keras.layers.Dense(380, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(220, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "dnn.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear regression (One layer-neuron perceptron)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_8 (Dense)              (None, 1)                 15        \n",
      "=================================================================\n",
      "Total params: 15\n",
      "Trainable params: 15\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "One neuron: 0.7850467289719626 %\n"
     ]
    }
   ],
   "source": [
    "olnp = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid', input_shape=[all_x.shape[1]])\n",
    "])\n",
    "olnp.summary()\n",
    "olnp.compile(optimizer='SGD', loss='mean_squared_error')\n",
    "olnp.fit(x_train, y_train, batch_size=50, steps_per_epoch=10, epochs=500, verbose=0)\n",
    "\n",
    "print('One neuron:', evaluate(olnp.predict(x_test).round().squeeze(), y_test), '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ordinary least squares regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "statsmodels: 0.7907303370786517 %\n"
     ]
    }
   ],
   "source": [
    "olsr = sm.OLS(y_train, x_train).fit()\n",
    "y_ols = olsr.predict(x_shuffle)\n",
    "print('statsmodels:', evaluate(y_ols.round(), y_shuffle), '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## My super dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maximize(arr):\n",
    "    d = np.append(arr, olsr.predict(arr).reshape(-1, 1), 1)\n",
    "    d = np.append(d, olnp.predict(arr).reshape(-1, 1), 1)\n",
    "    \n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.025  1.     0.     ... 0.     0.     0.    ]\n",
      " [0.0125 1.     0.     ... 0.     0.     0.    ]\n",
      " [0.4    0.     1.     ... 0.     0.     0.    ]\n",
      " ...\n",
      " [0.775  0.     1.     ... 0.     0.     0.    ]\n",
      " [0.3375 0.     0.     ... 0.     0.     0.    ]\n",
      " [0.2875 2.     0.     ... 0.     0.     0.    ]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(712, 16)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(x_shuffle)\n",
    "ds = maximize(x_shuffle)\n",
    "ds.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile (only or DNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_schedule = tf.keras.callbacks.LearningRateScheduler(\n",
    "    lambda epoch: 1e-8 * 10**(epoch / 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if(logs.get('loss')<0.11):\n",
    "            print(\"\\nReached 60% accuracy so cancelling training!\")\n",
    "            self.model.stop_training = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnn.compile(optimizer='SGD', loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train (DNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/600\n",
      "15/15 [==============================] - 1s 58ms/step - loss: 0.2424\n",
      "Epoch 2/600\n",
      "15/15 [==============================] - 1s 62ms/step - loss: 0.2422\n",
      "Epoch 3/600\n",
      "15/15 [==============================] - 1s 57ms/step - loss: 0.2416\n",
      "Epoch 4/600\n",
      "15/15 [==============================] - 1s 58ms/step - loss: 0.2413\n",
      "Epoch 5/600\n",
      "15/15 [==============================] - 1s 58ms/step - loss: 0.2409\n",
      "Epoch 6/600\n",
      "15/15 [==============================] - 1s 56ms/step - loss: 0.2405\n",
      "Epoch 7/600\n",
      "15/15 [==============================] - 1s 56ms/step - loss: 0.2399\n",
      "Epoch 8/600\n",
      "15/15 [==============================] - 1s 56ms/step - loss: 0.2392\n",
      "Epoch 9/600\n",
      "15/15 [==============================] - 1s 59ms/step - loss: 0.2387\n",
      "Epoch 10/600\n",
      "15/15 [==============================] - 1s 57ms/step - loss: 0.2383\n",
      "Epoch 11/600\n",
      "15/15 [==============================] - 1s 56ms/step - loss: 0.2378\n",
      "Epoch 12/600\n",
      "15/15 [==============================] - 1s 46ms/step - loss: 0.2373\n",
      "Epoch 13/600\n",
      "15/15 [==============================] - 1s 58ms/step - loss: 0.2368\n",
      "Epoch 14/600\n",
      "15/15 [==============================] - 1s 60ms/step - loss: 0.2364\n",
      "Epoch 15/600\n",
      "15/15 [==============================] - 1s 59ms/step - loss: 0.2357\n",
      "Epoch 16/600\n",
      "15/15 [==============================] - 1s 53ms/step - loss: 0.2351\n",
      "Epoch 17/600\n",
      "15/15 [==============================] - 1s 57ms/step - loss: 0.2349\n",
      "Epoch 18/600\n",
      "15/15 [==============================] - 1s 58ms/step - loss: 0.2341\n",
      "Epoch 19/600\n",
      "15/15 [==============================] - 1s 58ms/step - loss: 0.2335\n",
      "Epoch 20/600\n",
      "15/15 [==============================] - 1s 53ms/step - loss: 0.2329\n",
      "Epoch 21/600\n",
      "15/15 [==============================] - 1s 59ms/step - loss: 0.2325\n",
      "Epoch 22/600\n",
      "15/15 [==============================] - 1s 59ms/step - loss: 0.2313\n",
      "Epoch 23/600\n",
      "15/15 [==============================] - 1s 56ms/step - loss: 0.2308\n",
      "Epoch 24/600\n",
      "15/15 [==============================] - 1s 73ms/step - loss: 0.2296\n",
      "Epoch 25/600\n",
      "15/15 [==============================] - 1s 57ms/step - loss: 0.2292\n",
      "Epoch 26/600\n",
      "15/15 [==============================] - 1s 57ms/step - loss: 0.2284\n",
      "Epoch 27/600\n",
      "15/15 [==============================] - 1s 48ms/step - loss: 0.2278\n",
      "Epoch 28/600\n",
      "15/15 [==============================] - 1s 59ms/step - loss: 0.2269\n",
      "Epoch 29/600\n",
      "15/15 [==============================] - 1s 59ms/step - loss: 0.2258\n",
      "Epoch 30/600\n",
      "15/15 [==============================] - 1s 58ms/step - loss: 0.2247\n",
      "Epoch 31/600\n",
      "15/15 [==============================] - 1s 58ms/step - loss: 0.2241\n",
      "Epoch 32/600\n",
      "15/15 [==============================] - 1s 47ms/step - loss: 0.2233\n",
      "Epoch 33/600\n",
      "15/15 [==============================] - 1s 59ms/step - loss: 0.2221\n",
      "Epoch 34/600\n",
      "15/15 [==============================] - 1s 60ms/step - loss: 0.2209\n",
      "Epoch 35/600\n",
      "15/15 [==============================] - 1s 57ms/step - loss: 0.2200\n",
      "Epoch 36/600\n",
      "15/15 [==============================] - 1s 58ms/step - loss: 0.2186\n",
      "Epoch 37/600\n",
      "15/15 [==============================] - 1s 51ms/step - loss: 0.2171\n",
      "Epoch 38/600\n",
      "15/15 [==============================] - 1s 59ms/step - loss: 0.2161\n",
      "Epoch 39/600\n",
      "15/15 [==============================] - 1s 58ms/step - loss: 0.2150\n",
      "Epoch 40/600\n",
      "15/15 [==============================] - 1s 49ms/step - loss: 0.2136\n",
      "Epoch 41/600\n",
      "15/15 [==============================] - 1s 58ms/step - loss: 0.2121\n",
      "Epoch 42/600\n",
      "15/15 [==============================] - 1s 59ms/step - loss: 0.2108\n",
      "Epoch 43/600\n",
      "15/15 [==============================] - 1s 58ms/step - loss: 0.2092\n",
      "Epoch 44/600\n",
      "15/15 [==============================] - 1s 52ms/step - loss: 0.2086\n",
      "Epoch 45/600\n",
      "15/15 [==============================] - 1s 59ms/step - loss: 0.2066\n",
      "Epoch 46/600\n",
      "15/15 [==============================] - 1s 60ms/step - loss: 0.2045\n",
      "Epoch 47/600\n",
      "15/15 [==============================] - 1s 69ms/step - loss: 0.2032\n",
      "Epoch 48/600\n",
      "15/15 [==============================] - 1s 63ms/step - loss: 0.2014\n",
      "Epoch 49/600\n",
      "15/15 [==============================] - 1s 54ms/step - loss: 0.1995\n",
      "Epoch 50/600\n",
      "15/15 [==============================] - 1s 58ms/step - loss: 0.1982\n",
      "Epoch 51/600\n",
      "15/15 [==============================] - 1s 59ms/step - loss: 0.1968\n",
      "Epoch 52/600\n",
      "15/15 [==============================] - 1s 48ms/step - loss: 0.1947\n",
      "Epoch 53/600\n",
      "15/15 [==============================] - 1s 58ms/step - loss: 0.1919\n",
      "Epoch 54/600\n",
      "15/15 [==============================] - 1s 55ms/step - loss: 0.1905\n",
      "Epoch 55/600\n",
      "15/15 [==============================] - 1s 55ms/step - loss: 0.1886\n",
      "Epoch 56/600\n",
      "15/15 [==============================] - 1s 58ms/step - loss: 0.1863\n",
      "Epoch 57/600\n",
      "15/15 [==============================] - 1s 56ms/step - loss: 0.1846\n",
      "Epoch 58/600\n",
      "15/15 [==============================] - 1s 55ms/step - loss: 0.1832\n",
      "Epoch 59/600\n",
      "15/15 [==============================] - 1s 58ms/step - loss: 0.1811\n",
      "Epoch 60/600\n",
      "15/15 [==============================] - 1s 55ms/step - loss: 0.1792\n",
      "Epoch 61/600\n",
      "15/15 [==============================] - 1s 54ms/step - loss: 0.1772\n",
      "Epoch 62/600\n",
      "15/15 [==============================] - 1s 56ms/step - loss: 0.1763\n",
      "Epoch 63/600\n",
      "15/15 [==============================] - 1s 58ms/step - loss: 0.1727\n",
      "Epoch 64/600\n",
      "15/15 [==============================] - 1s 58ms/step - loss: 0.1722\n",
      "Epoch 65/600\n",
      "15/15 [==============================] - 1s 55ms/step - loss: 0.1703\n",
      "Epoch 66/600\n",
      "15/15 [==============================] - 1s 66ms/step - loss: 0.1688\n",
      "Epoch 67/600\n",
      "15/15 [==============================] - 1s 56ms/step - loss: 0.1678\n",
      "Epoch 68/600\n",
      "15/15 [==============================] - 1s 55ms/step - loss: 0.1645\n",
      "Epoch 69/600\n",
      "15/15 [==============================] - 1s 55ms/step - loss: 0.1634\n",
      "Epoch 70/600\n",
      "15/15 [==============================] - 1s 56ms/step - loss: 0.1629\n",
      "Epoch 71/600\n",
      "15/15 [==============================] - 1s 55ms/step - loss: 0.1604\n",
      "Epoch 72/600\n",
      "15/15 [==============================] - 1s 55ms/step - loss: 0.1594\n",
      "Epoch 73/600\n",
      "15/15 [==============================] - 1s 55ms/step - loss: 0.1571\n",
      "Epoch 74/600\n",
      "15/15 [==============================] - 1s 64ms/step - loss: 0.1553\n",
      "Epoch 75/600\n",
      "15/15 [==============================] - 1s 61ms/step - loss: 0.1538\n",
      "Epoch 76/600\n",
      "15/15 [==============================] - 1s 54ms/step - loss: 0.1536\n",
      "Epoch 77/600\n",
      "15/15 [==============================] - 1s 53ms/step - loss: 0.1525\n",
      "Epoch 78/600\n",
      "15/15 [==============================] - 1s 54ms/step - loss: 0.1515\n",
      "Epoch 79/600\n",
      "15/15 [==============================] - 1s 57ms/step - loss: 0.1512\n",
      "Epoch 80/600\n",
      "15/15 [==============================] - 1s 55ms/step - loss: 0.1491\n",
      "Epoch 81/600\n",
      "15/15 [==============================] - 1s 53ms/step - loss: 0.1490\n",
      "Epoch 82/600\n",
      "15/15 [==============================] - 1s 56ms/step - loss: 0.1493\n",
      "Epoch 83/600\n",
      "15/15 [==============================] - 1s 52ms/step - loss: 0.1480\n",
      "Epoch 84/600\n",
      "15/15 [==============================] - 1s 50ms/step - loss: 0.1465\n",
      "Epoch 85/600\n",
      "15/15 [==============================] - 1s 54ms/step - loss: 0.1454\n",
      "Epoch 86/600\n",
      "15/15 [==============================] - 1s 51ms/step - loss: 0.1437\n",
      "Epoch 87/600\n",
      "15/15 [==============================] - 1s 57ms/step - loss: 0.1445\n",
      "Epoch 88/600\n",
      "15/15 [==============================] - 1s 52ms/step - loss: 0.1446\n",
      "Epoch 89/600\n",
      "15/15 [==============================] - 1s 57ms/step - loss: 0.1446\n",
      "Epoch 90/600\n",
      "15/15 [==============================] - 1s 54ms/step - loss: 0.1426\n",
      "Epoch 91/600\n",
      "15/15 [==============================] - 1s 54ms/step - loss: 0.1420\n",
      "Epoch 92/600\n",
      "15/15 [==============================] - 1s 55ms/step - loss: 0.1438\n",
      "Epoch 93/600\n",
      "15/15 [==============================] - 1s 56ms/step - loss: 0.1399\n",
      "Epoch 94/600\n",
      "15/15 [==============================] - 1s 55ms/step - loss: 0.1409\n",
      "Epoch 95/600\n",
      "15/15 [==============================] - 1s 55ms/step - loss: 0.1407\n",
      "Epoch 96/600\n",
      "15/15 [==============================] - 1s 54ms/step - loss: 0.1394\n",
      "Epoch 97/600\n",
      "15/15 [==============================] - 1s 54ms/step - loss: 0.1382\n",
      "Epoch 98/600\n",
      "15/15 [==============================] - 1s 54ms/step - loss: 0.1396\n",
      "Epoch 99/600\n",
      "15/15 [==============================] - 1s 55ms/step - loss: 0.1388\n",
      "Epoch 100/600\n",
      "15/15 [==============================] - 1s 56ms/step - loss: 0.1377\n",
      "Epoch 101/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 1s 52ms/step - loss: 0.1370\n",
      "Epoch 102/600\n",
      "15/15 [==============================] - 1s 53ms/step - loss: 0.1372\n",
      "Epoch 103/600\n",
      "15/15 [==============================] - 1s 53ms/step - loss: 0.1382\n",
      "Epoch 104/600\n",
      "15/15 [==============================] - 1s 52ms/step - loss: 0.1375\n",
      "Epoch 105/600\n",
      "15/15 [==============================] - 1s 52ms/step - loss: 0.1363\n",
      "Epoch 106/600\n",
      "15/15 [==============================] - 1s 56ms/step - loss: 0.1358\n",
      "Epoch 107/600\n",
      "15/15 [==============================] - 1s 56ms/step - loss: 0.1367\n",
      "Epoch 108/600\n",
      "15/15 [==============================] - 1s 52ms/step - loss: 0.1362\n",
      "Epoch 109/600\n",
      "15/15 [==============================] - 1s 56ms/step - loss: 0.1343\n",
      "Epoch 110/600\n",
      "15/15 [==============================] - 1s 52ms/step - loss: 0.1363\n",
      "Epoch 111/600\n",
      "15/15 [==============================] - 1s 52ms/step - loss: 0.1364\n",
      "Epoch 112/600\n",
      "15/15 [==============================] - 1s 54ms/step - loss: 0.1342\n",
      "Epoch 113/600\n",
      "15/15 [==============================] - 1s 56ms/step - loss: 0.1362\n",
      "Epoch 114/600\n",
      "15/15 [==============================] - 1s 58ms/step - loss: 0.1333\n",
      "Epoch 115/600\n",
      "15/15 [==============================] - 1s 56ms/step - loss: 0.1358\n",
      "Epoch 116/600\n",
      "15/15 [==============================] - 1s 57ms/step - loss: 0.1337\n",
      "Epoch 117/600\n",
      "15/15 [==============================] - 1s 57ms/step - loss: 0.1337\n",
      "Epoch 118/600\n",
      "15/15 [==============================] - 1s 58ms/step - loss: 0.1353\n",
      "Epoch 119/600\n",
      "15/15 [==============================] - 1s 57ms/step - loss: 0.1370\n",
      "Epoch 120/600\n",
      "15/15 [==============================] - 1s 54ms/step - loss: 0.1337\n",
      "Epoch 121/600\n",
      "15/15 [==============================] - 1s 55ms/step - loss: 0.1325\n",
      "Epoch 122/600\n",
      "15/15 [==============================] - 1s 54ms/step - loss: 0.1322\n",
      "Epoch 123/600\n",
      "15/15 [==============================] - 1s 55ms/step - loss: 0.1332\n",
      "Epoch 124/600\n",
      "15/15 [==============================] - 1s 58ms/step - loss: 0.1329\n",
      "Epoch 125/600\n",
      "15/15 [==============================] - 1s 57ms/step - loss: 0.1325\n",
      "Epoch 126/600\n",
      "15/15 [==============================] - 1s 58ms/step - loss: 0.1331\n",
      "Epoch 127/600\n",
      "15/15 [==============================] - 1s 62ms/step - loss: 0.1340\n",
      "Epoch 128/600\n",
      "15/15 [==============================] - 1s 60ms/step - loss: 0.1308\n",
      "Epoch 129/600\n",
      "15/15 [==============================] - 1s 61ms/step - loss: 0.1321\n",
      "Epoch 130/600\n",
      "15/15 [==============================] - 1s 60ms/step - loss: 0.1319\n",
      "Epoch 131/600\n",
      "15/15 [==============================] - 1s 53ms/step - loss: 0.1330\n",
      "Epoch 132/600\n",
      "15/15 [==============================] - 1s 53ms/step - loss: 0.1329\n",
      "Epoch 133/600\n",
      "15/15 [==============================] - 1s 55ms/step - loss: 0.1308\n",
      "Epoch 134/600\n",
      "15/15 [==============================] - 1s 55ms/step - loss: 0.1314\n",
      "Epoch 135/600\n",
      "15/15 [==============================] - 1s 55ms/step - loss: 0.1329\n",
      "Epoch 136/600\n",
      "15/15 [==============================] - 1s 59ms/step - loss: 0.1307\n",
      "Epoch 137/600\n",
      "15/15 [==============================] - 1s 58ms/step - loss: 0.1307\n",
      "Epoch 138/600\n",
      "15/15 [==============================] - 1s 55ms/step - loss: 0.1320\n",
      "Epoch 139/600\n",
      "15/15 [==============================] - 1s 54ms/step - loss: 0.1324\n",
      "Epoch 140/600\n",
      "15/15 [==============================] - 1s 55ms/step - loss: 0.1304\n",
      "Epoch 141/600\n",
      "15/15 [==============================] - 1s 57ms/step - loss: 0.1314\n",
      "Epoch 142/600\n",
      "15/15 [==============================] - 1s 56ms/step - loss: 0.1333\n",
      "Epoch 143/600\n",
      "15/15 [==============================] - 1s 55ms/step - loss: 0.1309\n",
      "Epoch 144/600\n",
      "15/15 [==============================] - 1s 57ms/step - loss: 0.1298\n",
      "Epoch 145/600\n",
      "15/15 [==============================] - 1s 56ms/step - loss: 0.1302\n",
      "Epoch 146/600\n",
      "15/15 [==============================] - 1s 60ms/step - loss: 0.1313\n",
      "Epoch 147/600\n",
      "15/15 [==============================] - 1s 53ms/step - loss: 0.1306\n",
      "Epoch 148/600\n",
      "15/15 [==============================] - 1s 54ms/step - loss: 0.1287\n",
      "Epoch 149/600\n",
      "15/15 [==============================] - 1s 55ms/step - loss: 0.1322\n",
      "Epoch 150/600\n",
      "15/15 [==============================] - 1s 55ms/step - loss: 0.1315\n",
      "Epoch 151/600\n",
      "15/15 [==============================] - 1s 55ms/step - loss: 0.1291\n",
      "Epoch 152/600\n",
      "15/15 [==============================] - 1s 55ms/step - loss: 0.1297\n",
      "Epoch 153/600\n",
      "15/15 [==============================] - 1s 55ms/step - loss: 0.1312\n",
      "Epoch 154/600\n",
      "15/15 [==============================] - 1s 62ms/step - loss: 0.1292\n",
      "Epoch 155/600\n",
      "15/15 [==============================] - 1s 62ms/step - loss: 0.1306\n",
      "Epoch 156/600\n",
      "15/15 [==============================] - 1s 60ms/step - loss: 0.1292\n",
      "Epoch 157/600\n",
      "15/15 [==============================] - 1s 59ms/step - loss: 0.1290\n",
      "Epoch 158/600\n",
      "15/15 [==============================] - 1s 70ms/step - loss: 0.1307\n",
      "Epoch 159/600\n",
      "15/15 [==============================] - 1s 63ms/step - loss: 0.1304\n",
      "Epoch 160/600\n",
      "15/15 [==============================] - 1s 56ms/step - loss: 0.1318\n",
      "Epoch 161/600\n",
      "15/15 [==============================] - 1s 57ms/step - loss: 0.1299\n",
      "Epoch 162/600\n",
      "15/15 [==============================] - 1s 59ms/step - loss: 0.1307\n",
      "Epoch 163/600\n",
      "15/15 [==============================] - 1s 56ms/step - loss: 0.1298\n",
      "Epoch 164/600\n",
      "15/15 [==============================] - 1s 55ms/step - loss: 0.1281\n",
      "Epoch 165/600\n",
      "15/15 [==============================] - 1s 55ms/step - loss: 0.1303\n",
      "Epoch 166/600\n",
      "15/15 [==============================] - 1s 55ms/step - loss: 0.1291\n",
      "Epoch 167/600\n",
      "15/15 [==============================] - 1s 54ms/step - loss: 0.1293\n",
      "Epoch 168/600\n",
      "15/15 [==============================] - 1s 52ms/step - loss: 0.1280\n",
      "Epoch 169/600\n",
      "15/15 [==============================] - 1s 51ms/step - loss: 0.1284\n",
      "Epoch 170/600\n",
      "15/15 [==============================] - 1s 51ms/step - loss: 0.1285\n",
      "Epoch 171/600\n",
      "15/15 [==============================] - 1s 51ms/step - loss: 0.1295\n",
      "Epoch 172/600\n",
      "15/15 [==============================] - 1s 52ms/step - loss: 0.1295\n",
      "Epoch 173/600\n",
      "15/15 [==============================] - 1s 54ms/step - loss: 0.1287\n",
      "Epoch 174/600\n",
      "15/15 [==============================] - 1s 53ms/step - loss: 0.1276\n",
      "Epoch 175/600\n",
      "15/15 [==============================] - 1s 51ms/step - loss: 0.1295\n",
      "Epoch 176/600\n",
      "15/15 [==============================] - 1s 52ms/step - loss: 0.1276\n",
      "Epoch 177/600\n",
      "15/15 [==============================] - 1s 54ms/step - loss: 0.1285\n",
      "Epoch 178/600\n",
      "15/15 [==============================] - 1s 55ms/step - loss: 0.1300\n",
      "Epoch 179/600\n",
      "15/15 [==============================] - 1s 53ms/step - loss: 0.1289\n",
      "Epoch 180/600\n",
      "15/15 [==============================] - 1s 52ms/step - loss: 0.1300\n",
      "Epoch 181/600\n",
      "15/15 [==============================] - 1s 55ms/step - loss: 0.1279\n",
      "Epoch 182/600\n",
      "15/15 [==============================] - 1s 52ms/step - loss: 0.1277\n",
      "Epoch 183/600\n",
      "15/15 [==============================] - 1s 53ms/step - loss: 0.1293\n",
      "Epoch 184/600\n",
      "15/15 [==============================] - 1s 51ms/step - loss: 0.1268\n",
      "Epoch 185/600\n",
      "15/15 [==============================] - 1s 53ms/step - loss: 0.1273\n",
      "Epoch 186/600\n",
      "15/15 [==============================] - 1s 53ms/step - loss: 0.1294\n",
      "Epoch 187/600\n",
      "15/15 [==============================] - 1s 53ms/step - loss: 0.1267\n",
      "Epoch 188/600\n",
      "15/15 [==============================] - 1s 53ms/step - loss: 0.1297\n",
      "Epoch 189/600\n",
      "15/15 [==============================] - 1s 52ms/step - loss: 0.1261\n",
      "Epoch 190/600\n",
      "15/15 [==============================] - 1s 54ms/step - loss: 0.1275\n",
      "Epoch 191/600\n",
      "15/15 [==============================] - 1s 56ms/step - loss: 0.1271\n",
      "Epoch 192/600\n",
      "15/15 [==============================] - 1s 55ms/step - loss: 0.1268\n",
      "Epoch 193/600\n",
      "15/15 [==============================] - 1s 55ms/step - loss: 0.1289\n",
      "Epoch 194/600\n",
      "15/15 [==============================] - 1s 54ms/step - loss: 0.1283\n",
      "Epoch 195/600\n",
      "15/15 [==============================] - 1s 54ms/step - loss: 0.1257\n",
      "Epoch 196/600\n",
      "15/15 [==============================] - 1s 56ms/step - loss: 0.1282\n",
      "Epoch 197/600\n",
      "15/15 [==============================] - 1s 55ms/step - loss: 0.1264\n",
      "Epoch 198/600\n",
      "15/15 [==============================] - 1s 52ms/step - loss: 0.1281\n",
      "Epoch 199/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 1s 50ms/step - loss: 0.1278\n",
      "Epoch 200/600\n",
      "15/15 [==============================] - 1s 52ms/step - loss: 0.1269\n",
      "Epoch 201/600\n",
      "15/15 [==============================] - 1s 54ms/step - loss: 0.1261\n",
      "Epoch 202/600\n",
      "15/15 [==============================] - 1s 54ms/step - loss: 0.1274\n",
      "Epoch 203/600\n",
      "15/15 [==============================] - 1s 51ms/step - loss: 0.1273\n",
      "Epoch 204/600\n",
      "15/15 [==============================] - 1s 55ms/step - loss: 0.1272\n",
      "Epoch 205/600\n",
      "15/15 [==============================] - 1s 56ms/step - loss: 0.1274\n",
      "Epoch 206/600\n",
      "15/15 [==============================] - 1s 54ms/step - loss: 0.1280\n",
      "Epoch 207/600\n",
      "15/15 [==============================] - 1s 54ms/step - loss: 0.1256\n",
      "Epoch 208/600\n",
      "15/15 [==============================] - 1s 53ms/step - loss: 0.1274\n",
      "Epoch 209/600\n",
      "15/15 [==============================] - 1s 54ms/step - loss: 0.1277\n",
      "Epoch 210/600\n",
      "15/15 [==============================] - 1s 53ms/step - loss: 0.1244\n",
      "Epoch 211/600\n",
      "15/15 [==============================] - 1s 54ms/step - loss: 0.1257\n",
      "Epoch 212/600\n",
      "15/15 [==============================] - 1s 55ms/step - loss: 0.1231\n",
      "Epoch 213/600\n",
      "15/15 [==============================] - 1s 55ms/step - loss: 0.1264\n",
      "Epoch 214/600\n",
      "15/15 [==============================] - 1s 55ms/step - loss: 0.1263\n",
      "Epoch 215/600\n",
      "15/15 [==============================] - 1s 55ms/step - loss: 0.1265\n",
      "Epoch 216/600\n",
      "15/15 [==============================] - 1s 53ms/step - loss: 0.1265\n",
      "Epoch 217/600\n",
      "15/15 [==============================] - 1s 55ms/step - loss: 0.1257\n",
      "Epoch 218/600\n",
      "15/15 [==============================] - 1s 55ms/step - loss: 0.1271\n",
      "Epoch 219/600\n",
      "15/15 [==============================] - 1s 57ms/step - loss: 0.1260\n",
      "Epoch 220/600\n",
      "15/15 [==============================] - 1s 56ms/step - loss: 0.1269\n",
      "Epoch 221/600\n",
      "15/15 [==============================] - 1s 53ms/step - loss: 0.1246\n",
      "Epoch 222/600\n",
      "15/15 [==============================] - 1s 54ms/step - loss: 0.1264\n",
      "Epoch 223/600\n",
      "15/15 [==============================] - 1s 54ms/step - loss: 0.1260\n",
      "Epoch 224/600\n",
      "15/15 [==============================] - 1s 53ms/step - loss: 0.1238\n",
      "Epoch 225/600\n",
      "15/15 [==============================] - 1s 54ms/step - loss: 0.1256\n",
      "Epoch 226/600\n",
      "15/15 [==============================] - 1s 54ms/step - loss: 0.1262\n",
      "Epoch 227/600\n",
      "15/15 [==============================] - 1s 54ms/step - loss: 0.1265\n",
      "Epoch 228/600\n",
      "15/15 [==============================] - 1s 54ms/step - loss: 0.1256\n",
      "Epoch 229/600\n",
      "15/15 [==============================] - 1s 56ms/step - loss: 0.1236\n",
      "Epoch 230/600\n",
      "15/15 [==============================] - 1s 54ms/step - loss: 0.1257\n",
      "Epoch 231/600\n",
      "15/15 [==============================] - 1s 52ms/step - loss: 0.1255\n",
      "Epoch 232/600\n",
      "15/15 [==============================] - 1s 51ms/step - loss: 0.1271\n",
      "Epoch 233/600\n",
      "15/15 [==============================] - 1s 53ms/step - loss: 0.1280\n",
      "Epoch 234/600\n",
      "15/15 [==============================] - 1s 56ms/step - loss: 0.1259\n",
      "Epoch 235/600\n",
      "15/15 [==============================] - 1s 54ms/step - loss: 0.1245\n",
      "Epoch 236/600\n",
      "15/15 [==============================] - 1s 56ms/step - loss: 0.1276\n",
      "Epoch 237/600\n",
      "15/15 [==============================] - 1s 53ms/step - loss: 0.1242\n",
      "Epoch 238/600\n",
      "15/15 [==============================] - 1s 52ms/step - loss: 0.1250\n",
      "Epoch 239/600\n",
      "15/15 [==============================] - 1s 57ms/step - loss: 0.1253\n",
      "Epoch 240/600\n",
      "15/15 [==============================] - 1s 55ms/step - loss: 0.1255\n",
      "Epoch 241/600\n",
      "15/15 [==============================] - 1s 57ms/step - loss: 0.1251\n",
      "Epoch 242/600\n",
      "15/15 [==============================] - 1s 52ms/step - loss: 0.1254\n",
      "Epoch 243/600\n",
      "15/15 [==============================] - 1s 53ms/step - loss: 0.1267\n",
      "Epoch 244/600\n",
      "15/15 [==============================] - 1s 56ms/step - loss: 0.1254\n",
      "Epoch 245/600\n",
      "15/15 [==============================] - 1s 54ms/step - loss: 0.1252\n",
      "Epoch 246/600\n",
      "15/15 [==============================] - 1s 53ms/step - loss: 0.1259\n",
      "Epoch 247/600\n",
      "15/15 [==============================] - 1s 57ms/step - loss: 0.1255\n",
      "Epoch 248/600\n",
      "15/15 [==============================] - 1s 55ms/step - loss: 0.1253\n",
      "Epoch 249/600\n",
      "15/15 [==============================] - 1s 59ms/step - loss: 0.1253\n",
      "Epoch 250/600\n",
      "15/15 [==============================] - 1s 59ms/step - loss: 0.1247\n",
      "Epoch 251/600\n",
      "15/15 [==============================] - 1s 54ms/step - loss: 0.1254\n",
      "Epoch 252/600\n",
      "15/15 [==============================] - 1s 56ms/step - loss: 0.1237\n",
      "Epoch 253/600\n",
      "15/15 [==============================] - 1s 53ms/step - loss: 0.1245\n",
      "Epoch 254/600\n",
      "15/15 [==============================] - 1s 57ms/step - loss: 0.1262\n",
      "Epoch 255/600\n",
      "15/15 [==============================] - 1s 57ms/step - loss: 0.1255\n",
      "Epoch 256/600\n",
      "15/15 [==============================] - 1s 61ms/step - loss: 0.1251\n",
      "Epoch 257/600\n",
      "15/15 [==============================] - 1s 59ms/step - loss: 0.1268\n",
      "Epoch 258/600\n",
      "15/15 [==============================] - 1s 60ms/step - loss: 0.1247\n",
      "Epoch 259/600\n",
      "15/15 [==============================] - 1s 58ms/step - loss: 0.1256\n",
      "Epoch 260/600\n",
      "15/15 [==============================] - 1s 58ms/step - loss: 0.1236\n",
      "Epoch 261/600\n",
      "15/15 [==============================] - 1s 55ms/step - loss: 0.1251\n",
      "Epoch 262/600\n",
      "15/15 [==============================] - 1s 59ms/step - loss: 0.1253\n",
      "Epoch 263/600\n",
      "15/15 [==============================] - 1s 57ms/step - loss: 0.1256\n",
      "Epoch 264/600\n",
      "15/15 [==============================] - 1s 59ms/step - loss: 0.1263\n",
      "Epoch 265/600\n",
      "15/15 [==============================] - 1s 59ms/step - loss: 0.1244\n",
      "Epoch 266/600\n",
      "15/15 [==============================] - 1s 58ms/step - loss: 0.1266\n",
      "Epoch 267/600\n",
      "15/15 [==============================] - 1s 60ms/step - loss: 0.1248\n",
      "Epoch 268/600\n",
      "15/15 [==============================] - 1s 59ms/step - loss: 0.1262\n",
      "Epoch 269/600\n",
      "15/15 [==============================] - 1s 59ms/step - loss: 0.1241\n",
      "Epoch 270/600\n",
      "15/15 [==============================] - 1s 54ms/step - loss: 0.1254\n",
      "Epoch 271/600\n",
      "15/15 [==============================] - 1s 51ms/step - loss: 0.1257\n",
      "Epoch 272/600\n",
      "15/15 [==============================] - 1s 55ms/step - loss: 0.1257\n",
      "Epoch 273/600\n",
      "15/15 [==============================] - 1s 53ms/step - loss: 0.1215\n",
      "Epoch 274/600\n",
      "15/15 [==============================] - 1s 52ms/step - loss: 0.1220\n",
      "Epoch 275/600\n",
      "15/15 [==============================] - 1s 52ms/step - loss: 0.1249\n",
      "Epoch 276/600\n",
      "15/15 [==============================] - 1s 52ms/step - loss: 0.1251\n",
      "Epoch 277/600\n",
      "15/15 [==============================] - 1s 53ms/step - loss: 0.1250\n",
      "Epoch 278/600\n",
      "15/15 [==============================] - 1s 52ms/step - loss: 0.1257\n",
      "Epoch 279/600\n",
      "15/15 [==============================] - 1s 53ms/step - loss: 0.1239\n",
      "Epoch 280/600\n",
      "15/15 [==============================] - 1s 52ms/step - loss: 0.1243\n",
      "Epoch 281/600\n",
      "15/15 [==============================] - 1s 53ms/step - loss: 0.1222\n",
      "Epoch 282/600\n",
      "15/15 [==============================] - 1s 53ms/step - loss: 0.1256\n",
      "Epoch 283/600\n",
      "15/15 [==============================] - 1s 52ms/step - loss: 0.1254\n",
      "Epoch 284/600\n",
      "15/15 [==============================] - 1s 53ms/step - loss: 0.1243\n",
      "Epoch 285/600\n",
      "15/15 [==============================] - 1s 52ms/step - loss: 0.1264\n",
      "Epoch 286/600\n",
      "15/15 [==============================] - 1s 53ms/step - loss: 0.1246\n",
      "Epoch 287/600\n",
      "15/15 [==============================] - 1s 52ms/step - loss: 0.1235\n",
      "Epoch 288/600\n",
      "15/15 [==============================] - 1s 52ms/step - loss: 0.1224\n",
      "Epoch 289/600\n",
      "15/15 [==============================] - 1s 53ms/step - loss: 0.1259\n",
      "Epoch 290/600\n",
      "15/15 [==============================] - 1s 55ms/step - loss: 0.1255\n",
      "Epoch 291/600\n",
      "15/15 [==============================] - 1s 54ms/step - loss: 0.1229\n",
      "Epoch 292/600\n",
      "15/15 [==============================] - 1s 52ms/step - loss: 0.1249\n",
      "Epoch 293/600\n",
      "15/15 [==============================] - 1s 52ms/step - loss: 0.1237\n",
      "Epoch 294/600\n",
      "15/15 [==============================] - 1s 54ms/step - loss: 0.1246\n",
      "Epoch 295/600\n",
      "15/15 [==============================] - 1s 53ms/step - loss: 0.1237\n",
      "Epoch 296/600\n",
      "15/15 [==============================] - 1s 54ms/step - loss: 0.1235\n",
      "Epoch 297/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 1s 50ms/step - loss: 0.1238\n",
      "Epoch 298/600\n",
      "15/15 [==============================] - 1s 49ms/step - loss: 0.1225\n",
      "Epoch 299/600\n",
      "15/15 [==============================] - 1s 49ms/step - loss: 0.1236\n",
      "Epoch 300/600\n",
      "15/15 [==============================] - 1s 50ms/step - loss: 0.1239\n",
      "Epoch 301/600\n",
      "15/15 [==============================] - 1s 50ms/step - loss: 0.1253\n",
      "Epoch 302/600\n",
      "15/15 [==============================] - 1s 49ms/step - loss: 0.1209\n",
      "Epoch 303/600\n",
      "15/15 [==============================] - 1s 50ms/step - loss: 0.1245\n",
      "Epoch 304/600\n",
      "15/15 [==============================] - 1s 49ms/step - loss: 0.1242\n",
      "Epoch 305/600\n",
      "15/15 [==============================] - 1s 53ms/step - loss: 0.1221\n",
      "Epoch 306/600\n",
      "15/15 [==============================] - 1s 54ms/step - loss: 0.1247\n",
      "Epoch 307/600\n",
      "15/15 [==============================] - 1s 53ms/step - loss: 0.1237\n",
      "Epoch 308/600\n",
      "15/15 [==============================] - 1s 52ms/step - loss: 0.1238\n",
      "Epoch 309/600\n",
      "15/15 [==============================] - 1s 53ms/step - loss: 0.1226\n",
      "Epoch 310/600\n",
      "15/15 [==============================] - 1s 52ms/step - loss: 0.1218\n",
      "Epoch 311/600\n",
      "15/15 [==============================] - 1s 50ms/step - loss: 0.1249\n",
      "Epoch 312/600\n",
      "15/15 [==============================] - 1s 51ms/step - loss: 0.1248\n",
      "Epoch 313/600\n",
      "15/15 [==============================] - 1s 52ms/step - loss: 0.1240\n",
      "Epoch 314/600\n",
      "15/15 [==============================] - 1s 52ms/step - loss: 0.1234\n",
      "Epoch 315/600\n",
      "15/15 [==============================] - 1s 52ms/step - loss: 0.1235\n",
      "Epoch 316/600\n",
      "15/15 [==============================] - 1s 53ms/step - loss: 0.1237\n",
      "Epoch 317/600\n",
      "15/15 [==============================] - 1s 52ms/step - loss: 0.1251\n",
      "Epoch 318/600\n",
      "15/15 [==============================] - 1s 51ms/step - loss: 0.1244\n",
      "Epoch 319/600\n",
      "15/15 [==============================] - 1s 53ms/step - loss: 0.1222\n",
      "Epoch 320/600\n",
      "15/15 [==============================] - 1s 52ms/step - loss: 0.1244\n",
      "Epoch 321/600\n",
      "15/15 [==============================] - 1s 52ms/step - loss: 0.1223\n",
      "Epoch 322/600\n",
      "15/15 [==============================] - 1s 52ms/step - loss: 0.1242\n",
      "Epoch 323/600\n",
      "15/15 [==============================] - 1s 53ms/step - loss: 0.1242\n",
      "Epoch 324/600\n",
      "15/15 [==============================] - 1s 54ms/step - loss: 0.1234\n",
      "Epoch 325/600\n",
      "15/15 [==============================] - 1s 53ms/step - loss: 0.1230\n",
      "Epoch 326/600\n",
      "15/15 [==============================] - 1s 53ms/step - loss: 0.1230\n",
      "Epoch 327/600\n",
      "15/15 [==============================] - 1s 54ms/step - loss: 0.1246\n",
      "Epoch 328/600\n",
      "15/15 [==============================] - 1s 51ms/step - loss: 0.1247\n",
      "Epoch 329/600\n",
      "15/15 [==============================] - 1s 52ms/step - loss: 0.1244\n",
      "Epoch 330/600\n",
      "15/15 [==============================] - 1s 52ms/step - loss: 0.1239\n",
      "Epoch 331/600\n",
      "15/15 [==============================] - 1s 52ms/step - loss: 0.1223\n",
      "Epoch 332/600\n",
      "15/15 [==============================] - 1s 53ms/step - loss: 0.1226\n",
      "Epoch 333/600\n",
      "15/15 [==============================] - 1s 55ms/step - loss: 0.1250\n",
      "Epoch 334/600\n",
      "15/15 [==============================] - 1s 54ms/step - loss: 0.1226\n",
      "Epoch 335/600\n",
      "15/15 [==============================] - 1s 54ms/step - loss: 0.1246\n",
      "Epoch 336/600\n",
      "15/15 [==============================] - 1s 53ms/step - loss: 0.1233\n",
      "Epoch 337/600\n",
      "15/15 [==============================] - 1s 52ms/step - loss: 0.1234\n",
      "Epoch 338/600\n",
      "15/15 [==============================] - 1s 53ms/step - loss: 0.1227\n",
      "Epoch 339/600\n",
      "15/15 [==============================] - 1s 51ms/step - loss: 0.1222\n",
      "Epoch 340/600\n",
      "15/15 [==============================] - 1s 54ms/step - loss: 0.1220\n",
      "Epoch 341/600\n",
      "15/15 [==============================] - 1s 51ms/step - loss: 0.1228\n",
      "Epoch 342/600\n",
      "15/15 [==============================] - 1s 51ms/step - loss: 0.1220\n",
      "Epoch 343/600\n",
      "15/15 [==============================] - 1s 56ms/step - loss: 0.1230\n",
      "Epoch 344/600\n",
      "15/15 [==============================] - 1s 53ms/step - loss: 0.1233\n",
      "Epoch 345/600\n",
      "15/15 [==============================] - 1s 59ms/step - loss: 0.1258\n",
      "Epoch 346/600\n",
      "15/15 [==============================] - 1s 58ms/step - loss: 0.1253\n",
      "Epoch 347/600\n",
      "15/15 [==============================] - 1s 56ms/step - loss: 0.1221\n",
      "Epoch 348/600\n",
      "15/15 [==============================] - 1s 56ms/step - loss: 0.1223\n",
      "Epoch 349/600\n",
      "15/15 [==============================] - 1s 57ms/step - loss: 0.1246\n",
      "Epoch 350/600\n",
      "15/15 [==============================] - 1s 55ms/step - loss: 0.1236\n",
      "Epoch 351/600\n",
      "15/15 [==============================] - 1s 53ms/step - loss: 0.1236\n",
      "Epoch 352/600\n",
      "15/15 [==============================] - 1s 51ms/step - loss: 0.1214\n",
      "Epoch 353/600\n",
      "15/15 [==============================] - 1s 54ms/step - loss: 0.1252\n",
      "Epoch 354/600\n",
      "15/15 [==============================] - 1s 52ms/step - loss: 0.1246\n",
      "Epoch 355/600\n",
      "15/15 [==============================] - 1s 54ms/step - loss: 0.1231\n",
      "Epoch 356/600\n",
      "15/15 [==============================] - 1s 51ms/step - loss: 0.1234\n",
      "Epoch 357/600\n",
      "15/15 [==============================] - 1s 52ms/step - loss: 0.1254\n",
      "Epoch 358/600\n",
      "15/15 [==============================] - 1s 52ms/step - loss: 0.1257\n",
      "Epoch 359/600\n",
      "15/15 [==============================] - 1s 53ms/step - loss: 0.1239\n",
      "Epoch 360/600\n",
      "15/15 [==============================] - 1s 54ms/step - loss: 0.1241\n",
      "Epoch 361/600\n",
      "15/15 [==============================] - 1s 53ms/step - loss: 0.1227\n",
      "Epoch 362/600\n",
      "15/15 [==============================] - 1s 52ms/step - loss: 0.1229\n",
      "Epoch 363/600\n",
      "15/15 [==============================] - 1s 51ms/step - loss: 0.1234\n",
      "Epoch 364/600\n",
      "15/15 [==============================] - 1s 53ms/step - loss: 0.1247\n",
      "Epoch 365/600\n",
      "15/15 [==============================] - 1s 54ms/step - loss: 0.1225\n",
      "Epoch 366/600\n",
      "15/15 [==============================] - 1s 52ms/step - loss: 0.1247\n",
      "Epoch 367/600\n",
      "15/15 [==============================] - 1s 51ms/step - loss: 0.1223\n",
      "Epoch 368/600\n",
      "15/15 [==============================] - 1s 54ms/step - loss: 0.1222\n",
      "Epoch 369/600\n",
      "15/15 [==============================] - 1s 52ms/step - loss: 0.1207\n",
      "Epoch 370/600\n",
      "15/15 [==============================] - 1s 52ms/step - loss: 0.1235\n",
      "Epoch 371/600\n",
      "15/15 [==============================] - 1s 53ms/step - loss: 0.1233\n",
      "Epoch 372/600\n",
      "15/15 [==============================] - 1s 53ms/step - loss: 0.1228\n",
      "Epoch 373/600\n",
      "15/15 [==============================] - 1s 53ms/step - loss: 0.1239\n",
      "Epoch 374/600\n",
      "15/15 [==============================] - 1s 52ms/step - loss: 0.1231\n",
      "Epoch 375/600\n",
      "15/15 [==============================] - 1s 52ms/step - loss: 0.1216\n",
      "Epoch 376/600\n",
      "15/15 [==============================] - 1s 54ms/step - loss: 0.1212\n",
      "Epoch 377/600\n",
      "15/15 [==============================] - 1s 53ms/step - loss: 0.1232\n",
      "Epoch 378/600\n",
      "15/15 [==============================] - 1s 55ms/step - loss: 0.1229\n",
      "Epoch 379/600\n",
      "15/15 [==============================] - 1s 53ms/step - loss: 0.1233\n",
      "Epoch 380/600\n",
      "15/15 [==============================] - 1s 53ms/step - loss: 0.1220\n",
      "Epoch 381/600\n",
      "15/15 [==============================] - 1s 53ms/step - loss: 0.1230\n",
      "Epoch 382/600\n",
      "15/15 [==============================] - 1s 52ms/step - loss: 0.1239\n",
      "Epoch 383/600\n",
      "15/15 [==============================] - 1s 52ms/step - loss: 0.1230\n",
      "Epoch 384/600\n",
      "15/15 [==============================] - 1s 54ms/step - loss: 0.1242\n",
      "Epoch 385/600\n",
      "15/15 [==============================] - 1s 51ms/step - loss: 0.1231\n",
      "Epoch 386/600\n",
      "15/15 [==============================] - 1s 53ms/step - loss: 0.1231\n",
      "Epoch 387/600\n",
      "15/15 [==============================] - 1s 52ms/step - loss: 0.1230\n",
      "Epoch 388/600\n",
      "15/15 [==============================] - 1s 53ms/step - loss: 0.1238\n",
      "Epoch 389/600\n",
      "15/15 [==============================] - 1s 54ms/step - loss: 0.1220\n",
      "Epoch 390/600\n",
      "15/15 [==============================] - 1s 54ms/step - loss: 0.1213\n",
      "Epoch 391/600\n",
      "15/15 [==============================] - 1s 55ms/step - loss: 0.1234\n",
      "Epoch 392/600\n",
      "15/15 [==============================] - 1s 54ms/step - loss: 0.1236\n",
      "Epoch 393/600\n",
      "15/15 [==============================] - 1s 54ms/step - loss: 0.1218\n",
      "Epoch 394/600\n",
      "15/15 [==============================] - 1s 55ms/step - loss: 0.1223\n",
      "Epoch 395/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 1s 50ms/step - loss: 0.1245\n",
      "Epoch 396/600\n",
      "15/15 [==============================] - 1s 50ms/step - loss: 0.1230\n",
      "Epoch 397/600\n",
      "15/15 [==============================] - 1s 50ms/step - loss: 0.1232\n",
      "Epoch 398/600\n",
      "15/15 [==============================] - 1s 49ms/step - loss: 0.1228\n",
      "Epoch 399/600\n",
      "15/15 [==============================] - 1s 49ms/step - loss: 0.1218\n",
      "Epoch 400/600\n",
      "15/15 [==============================] - 1s 50ms/step - loss: 0.1256\n",
      "Epoch 401/600\n",
      "15/15 [==============================] - 1s 50ms/step - loss: 0.1229\n",
      "Epoch 402/600\n",
      "15/15 [==============================] - 1s 49ms/step - loss: 0.1201\n",
      "Epoch 403/600\n",
      "15/15 [==============================] - 1s 50ms/step - loss: 0.1217\n",
      "Epoch 404/600\n",
      "15/15 [==============================] - 1s 51ms/step - loss: 0.1228\n",
      "Epoch 405/600\n",
      "15/15 [==============================] - 1s 50ms/step - loss: 0.1231\n",
      "Epoch 406/600\n",
      "15/15 [==============================] - 1s 50ms/step - loss: 0.1218\n",
      "Epoch 407/600\n",
      "15/15 [==============================] - 1s 50ms/step - loss: 0.1221\n",
      "Epoch 408/600\n",
      "15/15 [==============================] - 1s 49ms/step - loss: 0.1224\n",
      "Epoch 409/600\n",
      "15/15 [==============================] - 1s 50ms/step - loss: 0.1231\n",
      "Epoch 410/600\n",
      "15/15 [==============================] - 1s 51ms/step - loss: 0.1235\n",
      "Epoch 411/600\n",
      "15/15 [==============================] - 1s 50ms/step - loss: 0.1228\n",
      "Epoch 412/600\n",
      "15/15 [==============================] - 1s 49ms/step - loss: 0.1234\n",
      "Epoch 413/600\n",
      "15/15 [==============================] - 1s 52ms/step - loss: 0.1235\n",
      "Epoch 414/600\n",
      "15/15 [==============================] - 1s 50ms/step - loss: 0.1233\n",
      "Epoch 415/600\n",
      "15/15 [==============================] - 1s 51ms/step - loss: 0.1227\n",
      "Epoch 416/600\n",
      "15/15 [==============================] - 1s 50ms/step - loss: 0.1225\n",
      "Epoch 417/600\n",
      "15/15 [==============================] - 1s 50ms/step - loss: 0.1216\n",
      "Epoch 418/600\n",
      "15/15 [==============================] - 1s 51ms/step - loss: 0.1236\n",
      "Epoch 419/600\n",
      "15/15 [==============================] - 1s 50ms/step - loss: 0.1241\n",
      "Epoch 420/600\n",
      "15/15 [==============================] - 1s 49ms/step - loss: 0.1224\n",
      "Epoch 421/600\n",
      "15/15 [==============================] - 1s 56ms/step - loss: 0.1203\n",
      "Epoch 422/600\n",
      "15/15 [==============================] - 1s 59ms/step - loss: 0.1223\n",
      "Epoch 423/600\n",
      "15/15 [==============================] - 1s 52ms/step - loss: 0.1233\n",
      "Epoch 424/600\n",
      "15/15 [==============================] - 1s 56ms/step - loss: 0.1220\n",
      "Epoch 425/600\n",
      "15/15 [==============================] - 1s 50ms/step - loss: 0.1229\n",
      "Epoch 426/600\n",
      "15/15 [==============================] - 1s 51ms/step - loss: 0.1236\n",
      "Epoch 427/600\n",
      "15/15 [==============================] - 1s 50ms/step - loss: 0.1205\n",
      "Epoch 428/600\n",
      "15/15 [==============================] - 1s 50ms/step - loss: 0.1221\n",
      "Epoch 429/600\n",
      "15/15 [==============================] - 1s 50ms/step - loss: 0.1210\n",
      "Epoch 430/600\n",
      "15/15 [==============================] - 1s 49ms/step - loss: 0.1249\n",
      "Epoch 431/600\n",
      "15/15 [==============================] - 1s 50ms/step - loss: 0.1210\n",
      "Epoch 432/600\n",
      "15/15 [==============================] - 1s 50ms/step - loss: 0.1227\n",
      "Epoch 433/600\n",
      "15/15 [==============================] - 1s 50ms/step - loss: 0.1214\n",
      "Epoch 434/600\n",
      "15/15 [==============================] - 1s 50ms/step - loss: 0.1211\n",
      "Epoch 435/600\n",
      "15/15 [==============================] - 1s 50ms/step - loss: 0.1226\n",
      "Epoch 436/600\n",
      "15/15 [==============================] - 1s 51ms/step - loss: 0.1219\n",
      "Epoch 437/600\n",
      "15/15 [==============================] - 1s 51ms/step - loss: 0.1217\n",
      "Epoch 438/600\n",
      "15/15 [==============================] - 1s 50ms/step - loss: 0.1217\n",
      "Epoch 439/600\n",
      "15/15 [==============================] - 1s 50ms/step - loss: 0.1220\n",
      "Epoch 440/600\n",
      "15/15 [==============================] - 1s 50ms/step - loss: 0.1206\n",
      "Epoch 441/600\n",
      "15/15 [==============================] - 1s 51ms/step - loss: 0.1206\n",
      "Epoch 442/600\n",
      "15/15 [==============================] - 1s 50ms/step - loss: 0.1222\n",
      "Epoch 443/600\n",
      "15/15 [==============================] - 1s 51ms/step - loss: 0.1226\n",
      "Epoch 444/600\n",
      "15/15 [==============================] - 1s 50ms/step - loss: 0.1191\n",
      "Epoch 445/600\n",
      "15/15 [==============================] - 1s 51ms/step - loss: 0.1212\n",
      "Epoch 446/600\n",
      "15/15 [==============================] - 1s 51ms/step - loss: 0.1227\n",
      "Epoch 447/600\n",
      "15/15 [==============================] - 1s 50ms/step - loss: 0.1210\n",
      "Epoch 448/600\n",
      "15/15 [==============================] - 1s 50ms/step - loss: 0.1222\n",
      "Epoch 449/600\n",
      "15/15 [==============================] - 1s 50ms/step - loss: 0.1219\n",
      "Epoch 450/600\n",
      "15/15 [==============================] - 1s 50ms/step - loss: 0.1209\n",
      "Epoch 451/600\n",
      "15/15 [==============================] - 1s 50ms/step - loss: 0.1237\n",
      "Epoch 452/600\n",
      "15/15 [==============================] - 1s 51ms/step - loss: 0.1210\n",
      "Epoch 453/600\n",
      "15/15 [==============================] - 1s 51ms/step - loss: 0.1213\n",
      "Epoch 454/600\n",
      "15/15 [==============================] - 1s 51ms/step - loss: 0.1202\n",
      "Epoch 455/600\n",
      "15/15 [==============================] - 1s 51ms/step - loss: 0.1236\n",
      "Epoch 456/600\n",
      "15/15 [==============================] - 1s 50ms/step - loss: 0.1209\n",
      "Epoch 457/600\n",
      "15/15 [==============================] - 1s 52ms/step - loss: 0.1218\n",
      "Epoch 458/600\n",
      "15/15 [==============================] - 1s 51ms/step - loss: 0.1215\n",
      "Epoch 459/600\n",
      "15/15 [==============================] - 1s 51ms/step - loss: 0.1220\n",
      "Epoch 460/600\n",
      "15/15 [==============================] - 1s 50ms/step - loss: 0.1220\n",
      "Epoch 461/600\n",
      "15/15 [==============================] - 1s 50ms/step - loss: 0.1210\n",
      "Epoch 462/600\n",
      "15/15 [==============================] - 1s 50ms/step - loss: 0.1213\n",
      "Epoch 463/600\n",
      "15/15 [==============================] - 1s 50ms/step - loss: 0.1217\n",
      "Epoch 464/600\n",
      "15/15 [==============================] - 1s 51ms/step - loss: 0.1234\n",
      "Epoch 465/600\n",
      "15/15 [==============================] - 1s 51ms/step - loss: 0.1218\n",
      "Epoch 466/600\n",
      "15/15 [==============================] - 1s 50ms/step - loss: 0.1215\n",
      "Epoch 467/600\n",
      "15/15 [==============================] - 1s 50ms/step - loss: 0.1225\n",
      "Epoch 468/600\n",
      "15/15 [==============================] - 1s 50ms/step - loss: 0.1216\n",
      "Epoch 469/600\n",
      "15/15 [==============================] - 1s 53ms/step - loss: 0.1216\n",
      "Epoch 470/600\n",
      "15/15 [==============================] - 1s 50ms/step - loss: 0.1219\n",
      "Epoch 471/600\n",
      "15/15 [==============================] - 1s 51ms/step - loss: 0.1236\n",
      "Epoch 472/600\n",
      "15/15 [==============================] - 1s 50ms/step - loss: 0.1216\n",
      "Epoch 473/600\n",
      "15/15 [==============================] - 1s 51ms/step - loss: 0.1224\n",
      "Epoch 474/600\n",
      "15/15 [==============================] - 1s 55ms/step - loss: 0.1211\n",
      "Epoch 475/600\n",
      "15/15 [==============================] - 1s 68ms/step - loss: 0.1225\n",
      "Epoch 476/600\n",
      "15/15 [==============================] - 1s 60ms/step - loss: 0.1238\n",
      "Epoch 477/600\n",
      "15/15 [==============================] - 1s 58ms/step - loss: 0.1213\n",
      "Epoch 478/600\n",
      "15/15 [==============================] - 1s 58ms/step - loss: 0.1225\n",
      "Epoch 479/600\n",
      "15/15 [==============================] - 1s 59ms/step - loss: 0.1215\n",
      "Epoch 480/600\n",
      "15/15 [==============================] - 1s 56ms/step - loss: 0.1240\n",
      "Epoch 481/600\n",
      "15/15 [==============================] - 1s 52ms/step - loss: 0.1218\n",
      "Epoch 482/600\n",
      "15/15 [==============================] - 1s 55ms/step - loss: 0.1198\n",
      "Epoch 483/600\n",
      "15/15 [==============================] - 1s 55ms/step - loss: 0.1203\n",
      "Epoch 484/600\n",
      "15/15 [==============================] - 1s 55ms/step - loss: 0.1200\n",
      "Epoch 485/600\n",
      "15/15 [==============================] - 1s 54ms/step - loss: 0.1227\n",
      "Epoch 486/600\n",
      "15/15 [==============================] - 1s 54ms/step - loss: 0.1217\n",
      "Epoch 487/600\n",
      "15/15 [==============================] - 1s 54ms/step - loss: 0.1197\n",
      "Epoch 488/600\n",
      "15/15 [==============================] - 1s 52ms/step - loss: 0.1232\n",
      "Epoch 489/600\n",
      "15/15 [==============================] - 1s 54ms/step - loss: 0.1227\n",
      "Epoch 490/600\n",
      "15/15 [==============================] - 1s 54ms/step - loss: 0.1220\n",
      "Epoch 491/600\n",
      "15/15 [==============================] - 1s 52ms/step - loss: 0.1213\n",
      "Epoch 492/600\n",
      "15/15 [==============================] - 1s 57ms/step - loss: 0.1205\n",
      "Epoch 493/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 1s 62ms/step - loss: 0.1218\n",
      "Epoch 494/600\n",
      "15/15 [==============================] - 1s 49ms/step - loss: 0.1212\n",
      "Epoch 495/600\n",
      "15/15 [==============================] - 1s 52ms/step - loss: 0.1195\n",
      "Epoch 496/600\n",
      "15/15 [==============================] - 1s 48ms/step - loss: 0.1209\n",
      "Epoch 497/600\n",
      "15/15 [==============================] - 1s 52ms/step - loss: 0.1203\n",
      "Epoch 498/600\n",
      "15/15 [==============================] - 1s 48ms/step - loss: 0.1210\n",
      "Epoch 499/600\n",
      "15/15 [==============================] - 1s 52ms/step - loss: 0.1201\n",
      "Epoch 500/600\n",
      "15/15 [==============================] - 1s 48ms/step - loss: 0.1204\n",
      "Epoch 501/600\n",
      "15/15 [==============================] - 1s 49ms/step - loss: 0.1211\n",
      "Epoch 502/600\n",
      "15/15 [==============================] - 1s 52ms/step - loss: 0.1218\n",
      "Epoch 503/600\n",
      "15/15 [==============================] - 1s 51ms/step - loss: 0.1199\n",
      "Epoch 504/600\n",
      "15/15 [==============================] - 1s 51ms/step - loss: 0.1225\n",
      "Epoch 505/600\n",
      "15/15 [==============================] - 1s 49ms/step - loss: 0.1209\n",
      "Epoch 506/600\n",
      "15/15 [==============================] - 1s 51ms/step - loss: 0.1213\n",
      "Epoch 507/600\n",
      "15/15 [==============================] - 1s 52ms/step - loss: 0.1217\n",
      "Epoch 508/600\n",
      "15/15 [==============================] - 1s 50ms/step - loss: 0.1192\n",
      "Epoch 509/600\n",
      "15/15 [==============================] - 1s 50ms/step - loss: 0.1212\n",
      "Epoch 510/600\n",
      "15/15 [==============================] - 1s 49ms/step - loss: 0.1199\n",
      "Epoch 511/600\n",
      "15/15 [==============================] - 1s 51ms/step - loss: 0.1206\n",
      "Epoch 512/600\n",
      "15/15 [==============================] - 1s 50ms/step - loss: 0.1232\n",
      "Epoch 513/600\n",
      "15/15 [==============================] - 1s 50ms/step - loss: 0.1202\n",
      "Epoch 514/600\n",
      "15/15 [==============================] - 1s 49ms/step - loss: 0.1216\n",
      "Epoch 515/600\n",
      "15/15 [==============================] - 1s 50ms/step - loss: 0.1217\n",
      "Epoch 516/600\n",
      "15/15 [==============================] - 1s 52ms/step - loss: 0.1199\n",
      "Epoch 517/600\n",
      "15/15 [==============================] - 1s 50ms/step - loss: 0.1225\n",
      "Epoch 518/600\n",
      "15/15 [==============================] - 1s 63ms/step - loss: 0.1200\n",
      "Epoch 519/600\n",
      "15/15 [==============================] - 1s 55ms/step - loss: 0.1223\n",
      "Epoch 520/600\n",
      "15/15 [==============================] - 1s 52ms/step - loss: 0.1218\n",
      "Epoch 521/600\n",
      "15/15 [==============================] - 1s 67ms/step - loss: 0.1211\n",
      "Epoch 522/600\n",
      "15/15 [==============================] - 1s 56ms/step - loss: 0.1224\n",
      "Epoch 523/600\n",
      "15/15 [==============================] - 1s 54ms/step - loss: 0.1200\n",
      "Epoch 524/600\n",
      "15/15 [==============================] - 1s 55ms/step - loss: 0.1211\n",
      "Epoch 525/600\n",
      "15/15 [==============================] - 1s 54ms/step - loss: 0.1205\n",
      "Epoch 526/600\n",
      "15/15 [==============================] - 1s 54ms/step - loss: 0.1210\n",
      "Epoch 527/600\n",
      "15/15 [==============================] - 1s 51ms/step - loss: 0.1199\n",
      "Epoch 528/600\n",
      "15/15 [==============================] - 1s 55ms/step - loss: 0.1224\n",
      "Epoch 529/600\n",
      "15/15 [==============================] - 1s 52ms/step - loss: 0.1213\n",
      "Epoch 530/600\n",
      "15/15 [==============================] - 1s 54ms/step - loss: 0.1225\n",
      "Epoch 531/600\n",
      "15/15 [==============================] - 1s 53ms/step - loss: 0.1192\n",
      "Epoch 532/600\n",
      "15/15 [==============================] - 1s 52ms/step - loss: 0.1199\n",
      "Epoch 533/600\n",
      "15/15 [==============================] - 1s 55ms/step - loss: 0.1219\n",
      "Epoch 534/600\n",
      "15/15 [==============================] - 1s 53ms/step - loss: 0.1207\n",
      "Epoch 535/600\n",
      "15/15 [==============================] - 1s 53ms/step - loss: 0.1197\n",
      "Epoch 536/600\n",
      "15/15 [==============================] - 1s 54ms/step - loss: 0.1212\n",
      "Epoch 537/600\n",
      "15/15 [==============================] - 1s 51ms/step - loss: 0.1226\n",
      "Epoch 538/600\n",
      "15/15 [==============================] - 1s 54ms/step - loss: 0.1209\n",
      "Epoch 539/600\n",
      "15/15 [==============================] - 1s 53ms/step - loss: 0.1205\n",
      "Epoch 540/600\n",
      "15/15 [==============================] - 1s 52ms/step - loss: 0.1211\n",
      "Epoch 541/600\n",
      "15/15 [==============================] - 1s 53ms/step - loss: 0.1216\n",
      "Epoch 542/600\n",
      "15/15 [==============================] - 1s 54ms/step - loss: 0.1228\n",
      "Epoch 543/600\n",
      "15/15 [==============================] - 1s 53ms/step - loss: 0.1207\n",
      "Epoch 544/600\n",
      "15/15 [==============================] - 1s 52ms/step - loss: 0.1218\n",
      "Epoch 545/600\n",
      "15/15 [==============================] - 1s 55ms/step - loss: 0.1226\n",
      "Epoch 546/600\n",
      "15/15 [==============================] - 1s 53ms/step - loss: 0.1213\n",
      "Epoch 547/600\n",
      "15/15 [==============================] - 1s 52ms/step - loss: 0.1216\n",
      "Epoch 548/600\n",
      "15/15 [==============================] - 1s 53ms/step - loss: 0.1206\n",
      "Epoch 549/600\n",
      "15/15 [==============================] - 1s 55ms/step - loss: 0.1212\n",
      "Epoch 550/600\n",
      "15/15 [==============================] - 1s 51ms/step - loss: 0.1209\n",
      "Epoch 551/600\n",
      "15/15 [==============================] - 1s 52ms/step - loss: 0.1207\n",
      "Epoch 552/600\n",
      "15/15 [==============================] - 1s 54ms/step - loss: 0.1196\n",
      "Epoch 553/600\n",
      "15/15 [==============================] - 1s 52ms/step - loss: 0.1209\n",
      "Epoch 554/600\n",
      "15/15 [==============================] - 1s 51ms/step - loss: 0.1224\n",
      "Epoch 555/600\n",
      "15/15 [==============================] - 1s 55ms/step - loss: 0.1198\n",
      "Epoch 556/600\n",
      "15/15 [==============================] - 1s 53ms/step - loss: 0.1200\n",
      "Epoch 557/600\n",
      "15/15 [==============================] - 1s 51ms/step - loss: 0.1213\n",
      "Epoch 558/600\n",
      "15/15 [==============================] - 1s 54ms/step - loss: 0.1212\n",
      "Epoch 559/600\n",
      "15/15 [==============================] - 1s 52ms/step - loss: 0.1204\n",
      "Epoch 560/600\n",
      "15/15 [==============================] - 1s 53ms/step - loss: 0.1211\n",
      "Epoch 561/600\n",
      "15/15 [==============================] - 1s 55ms/step - loss: 0.1211\n",
      "Epoch 562/600\n",
      "15/15 [==============================] - 1s 54ms/step - loss: 0.1227\n",
      "Epoch 563/600\n",
      "15/15 [==============================] - 1s 50ms/step - loss: 0.1217\n",
      "Epoch 564/600\n",
      "15/15 [==============================] - 1s 54ms/step - loss: 0.1214\n",
      "Epoch 565/600\n",
      "15/15 [==============================] - 1s 52ms/step - loss: 0.1198\n",
      "Epoch 566/600\n",
      "15/15 [==============================] - 1s 52ms/step - loss: 0.1206\n",
      "Epoch 567/600\n",
      "15/15 [==============================] - 1s 56ms/step - loss: 0.1190\n",
      "Epoch 568/600\n",
      "15/15 [==============================] - 1s 53ms/step - loss: 0.1213\n",
      "Epoch 569/600\n",
      "15/15 [==============================] - 1s 53ms/step - loss: 0.1215\n",
      "Epoch 570/600\n",
      "15/15 [==============================] - 1s 55ms/step - loss: 0.1216\n",
      "Epoch 571/600\n",
      "15/15 [==============================] - 1s 54ms/step - loss: 0.1220\n",
      "Epoch 572/600\n",
      "15/15 [==============================] - 1s 55ms/step - loss: 0.1194\n",
      "Epoch 573/600\n",
      "15/15 [==============================] - 1s 54ms/step - loss: 0.1213\n",
      "Epoch 574/600\n",
      "15/15 [==============================] - 1s 53ms/step - loss: 0.1218\n",
      "Epoch 575/600\n",
      "15/15 [==============================] - 1s 53ms/step - loss: 0.1203\n",
      "Epoch 576/600\n",
      "15/15 [==============================] - 1s 54ms/step - loss: 0.1202\n",
      "Epoch 577/600\n",
      "15/15 [==============================] - 1s 54ms/step - loss: 0.1211\n",
      "Epoch 578/600\n",
      "15/15 [==============================] - 1s 51ms/step - loss: 0.1200\n",
      "Epoch 579/600\n",
      "15/15 [==============================] - 1s 55ms/step - loss: 0.1214\n",
      "Epoch 580/600\n",
      "15/15 [==============================] - 1s 52ms/step - loss: 0.1216\n",
      "Epoch 581/600\n",
      "15/15 [==============================] - 1s 52ms/step - loss: 0.1204\n",
      "Epoch 582/600\n",
      "15/15 [==============================] - 1s 55ms/step - loss: 0.1202\n",
      "Epoch 583/600\n",
      "15/15 [==============================] - 1s 52ms/step - loss: 0.1214\n",
      "Epoch 584/600\n",
      "15/15 [==============================] - 1s 53ms/step - loss: 0.1207\n",
      "Epoch 585/600\n",
      "15/15 [==============================] - 1s 54ms/step - loss: 0.1225\n",
      "Epoch 586/600\n",
      "15/15 [==============================] - 1s 53ms/step - loss: 0.1202\n",
      "Epoch 587/600\n",
      "15/15 [==============================] - 1s 54ms/step - loss: 0.1205\n",
      "Epoch 588/600\n",
      "15/15 [==============================] - 1s 55ms/step - loss: 0.1222\n",
      "Epoch 589/600\n",
      "15/15 [==============================] - 1s 57ms/step - loss: 0.1215\n",
      "Epoch 590/600\n",
      "15/15 [==============================] - 1s 54ms/step - loss: 0.1206\n",
      "Epoch 591/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 1s 58ms/step - loss: 0.1201\n",
      "Epoch 592/600\n",
      "15/15 [==============================] - 1s 59ms/step - loss: 0.1212\n",
      "Epoch 593/600\n",
      "15/15 [==============================] - 1s 57ms/step - loss: 0.1199\n",
      "Epoch 594/600\n",
      "15/15 [==============================] - 1s 55ms/step - loss: 0.1210\n",
      "Epoch 595/600\n",
      "15/15 [==============================] - 1s 55ms/step - loss: 0.1199\n",
      "Epoch 596/600\n",
      "15/15 [==============================] - 1s 55ms/step - loss: 0.1207\n",
      "Epoch 597/600\n",
      "15/15 [==============================] - 1s 51ms/step - loss: 0.1206\n",
      "Epoch 598/600\n",
      "15/15 [==============================] - 1s 53ms/step - loss: 0.1207\n",
      "Epoch 599/600\n",
      "15/15 [==============================] - 1s 52ms/step - loss: 0.1201\n",
      "Epoch 600/600\n",
      "15/15 [==============================] - 1s 56ms/step - loss: 0.1207\n",
      "Evaluation:\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.1189\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cback = myCallback()\n",
    "history = dnn.fit(ds, y_shuffle, batch_size=50, steps_per_epoch=15, epochs=600, callbacks=[cback])\n",
    "print('Evaluation:')\n",
    "dnn.evaluate(ds, y_shuffle)\n",
    "\n",
    "#plot\n",
    "plt.plot(history.history['loss'])\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.title('Model loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.8353413654618473 %\n",
      "Testing accuracy: 0.8411214953271028 %\n"
     ]
    }
   ],
   "source": [
    "def dummyCheck(array, compareBy):\n",
    "    array = dnn.predict(array)\n",
    "\n",
    "    predictions = map(lambda x: np.squeeze(x).round(), array)\n",
    "    predictions = np.array(list(predictions))\n",
    "\n",
    "    return predictions == np.array(compareBy)\n",
    "\n",
    "\n",
    "dds = maximize(x_train)\n",
    "ddsT = maximize(x_test)\n",
    "\n",
    "# print(y_train.shape, x_train.shape, dds.shape, dnn.predict(dds).shape, y_train.shape)\n",
    "# print(y_test.shape, x_test.shape, ddsT.shape, dnn.predict(ddsT).shape, y_test.shape)\n",
    "\n",
    "print('Training accuracy:', sum(dummyCheck(dds, y_train)) / len(y_train), '%')\n",
    "print('Testing accuracy:', sum(dummyCheck(ddsT, y_test)) / len(y_test), '%')\n",
    "\n",
    "# DNN x10 Combined\n",
    "# Training accuracy: 0.8373493975903614 %\n",
    "# Testing accuracy: 0.8504672897196262 %\n",
    "\n",
    "# DNN neurons 10x - p-value optimized\n",
    "# Training accuracy: 0.8373493975903614 %\n",
    "# Testing accuracy: 0.8317757009345794 %\n",
    "\n",
    "# DNN neurons 10x - p-value partial optimized\n",
    "# Training accuracy: 0.8132530120481928 %\n",
    "# Testing accuracy: 0.8317757009345794 %\n",
    "\n",
    "# DNN neurons 10x\n",
    "# Training accuracy: 0.7951807228915663 %\n",
    "# Testing accuracy: 0.8271028037383178 %\n",
    "\n",
    "# DNN \n",
    "# Training accuracy: 0.7409638554216867 %\n",
    "# Testing accuracy: 0.7850467289719626 %\n",
    "\n",
    "# Linear Regression\n",
    "# Training accuracy: 0.7871485943775101 %\n",
    "# Testing accuracy: 0.7850467289719626 %"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the model (DNN 10x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DNN10x_and_regressions.h5  DNN10x.h5  DNN10x_pvalue.h5\r\n"
     ]
    }
   ],
   "source": [
    "!ls *.h5\n",
    "dnn.save('DNN10x_and_regressions.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = tf.keras.models.load_model('DNN10x_pvalue.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make predictions file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cabin_A23\n",
      "Cabin_C49\n",
      "Cabin_D56\n",
      "Cabin_E10\n",
      "Cabin_E25\n",
      "0.2631578947368421 % will be survive\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>1305</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>1306</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>1307</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>1308</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>1309</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>418 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived\n",
       "0            892         0\n",
       "1            893         0\n",
       "2            894         0\n",
       "3            895         0\n",
       "4            896         0\n",
       "..           ...       ...\n",
       "413         1305         0\n",
       "414         1306         1\n",
       "415         1307         0\n",
       "416         1308         0\n",
       "417         1309         0\n",
       "\n",
       "[418 rows x 2 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfTesting = pd.read_csv('test.csv')\n",
    "\n",
    "dfResult = pd.DataFrame()\n",
    "dfResult['PassengerId'] = dfTesting['PassengerId']\n",
    "\n",
    "dfTesting = processDf(dfTesting, False)\n",
    "\n",
    "ds = np.append(dfTesting['x_train'], olsr.predict(dfTesting['x_train']).reshape(-1, 1), 1)\n",
    "ds = np.append(ds, olnp.predict(dfTesting['x_train']).reshape(-1, 1), 1)\n",
    "\n",
    "assert len(ds[0]) == dnn.input_shape[1]\n",
    "\n",
    "# 0.2894736842105263 % will be survive\n",
    "# 0.4044943820224719 % survived in real data\n",
    "\n",
    "dfResult['Survived'] = dnn.predict(ds).round().astype(int)\n",
    "\n",
    "print(dfResult['Survived'].sum()/len(dfResult['Survived']), '% will be survive')\n",
    "\n",
    "dfResult.to_csv('result_mean_multi.csv', index=False)\n",
    "\n",
    "dfResult"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
